import pandas as pd
import numpy as np


message=pd.read_csv("SMSSpamCollection.csv")
message


import re
import nltk
nltk.download('stopwords')


from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
lm=WordNetLemmatizer()
nltk.download('wordnet')


corpus = []
for msg in message['message']:   # use correct column name
    words = nltk.word_tokenize(msg.lower())
    words = [lm.lemmatize(w) for w in words if w.isalpha()]
    corpus.append(words)



print(corpus[0])


from gensim.models import Word2Vec

model = Word2Vec(
    sentences=corpus,
    vector_size=100,
    window=5,
    min_count=2
)



model.wv.index_to_key[1]


model.epochs


model.wv.similar_by_word('kid')


def get_vector(sentence):
    vectors = []
    for word in sentence:
        if word in w2v_model.wv:
            vectors.append(w2v_model.wv[word])
    if len(vectors) == 0:
        return np.zeros(100)
    return np.mean(vectors, axis=0)



Y = message[list(map(lambda x: len(x)>0 ,corpus))]
Y=pd.get_dummies(Y['label'])
Y=Y.iloc[:,1].values


## train test split 
from sklearn.model_selection import train_test_split
X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=30)


from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier()
model.fit(X_train, Y_train)



print(X.shape, Y.shape)
print(X_train.shape, X_test.shape)




