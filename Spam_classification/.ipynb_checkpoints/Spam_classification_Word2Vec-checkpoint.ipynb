{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "31839239-0b6e-4000-a4d3-ec9a313ddff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e69ac249-0579-44da-94f0-3b60dde1485f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>spam</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>ham</td>\n",
       "      <td>Will ü b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>ham</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5572</th>\n",
       "      <td>ham</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5573</th>\n",
       "      <td>ham</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5574 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label                                            message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5569  spam  This is the 2nd time we have tried 2 contact u...\n",
       "5570   ham               Will ü b going to esplanade fr home?\n",
       "5571   ham  Pity, * was in mood for that. So...any other s...\n",
       "5572   ham  The guy did some bitching but I acted like i'd...\n",
       "5573   ham                         Rofl. Its true to its name\n",
       "\n",
       "[5574 rows x 2 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message=pd.read_csv(\"SMSSpamCollection.csv\")\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7ce7a7e5-9522-43fb-a6ce-e2b77c2f60f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b23e60fe-14d8-41c5-8816-e6024e806683",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\LENOVO\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lm=WordNetLemmatizer()\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e95baa00-ce08-4d8d-b5e3-3c7e4420079e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(0,len(message)):\n",
    "    clean_data=re.sub('[^a-zA-Z0-9]',' ',message['message'][i])\n",
    "    clean_data=clean_data.lower()\n",
    "    clean_data=clean_data.split()\n",
    "    clean_data=[lm.lemmatize(word) for word in clean_data if not word in (stopwords.words('english')) ]\n",
    "    clean_data=' '.join(clean_data)\n",
    "    corpus.append(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "b6c621e3-816d-49ed-8bd2-43e9ced8c2fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go jurong point crazy available bugis n great world la e buffet cine got amore wat\n"
     ]
    }
   ],
   "source": [
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "bf07a3b1-b47c-4d24-b77d-bc1e6b629e95",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, '', 'What you doing?how are you?'],\n",
       " [0, '', 'Where @'],\n",
       " [0, '', 'Can a not?'],\n",
       " [0, '', ':)'],\n",
       " [0, '', 'What you doing?how are you?'],\n",
       " [0, '', ':( but your not here....'],\n",
       " [0, '', ':-) :-)']]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[[i,j,k] for i,j,k in zip(list(map(len,corpus)),corpus, message['message']) if i<1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "cddb03a5-c02e-4943-9d21-5add41dd9e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import sent_tokenize\n",
    "from gensim.utils import simple_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6f809c94-f196-414c-9666-962bf63a3755",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=[]\n",
    "for sent in corpus:\n",
    "    sent_token=sent_tokenize(sent)\n",
    "    for sent in sent_token:\n",
    "        words.append(simple_preprocess(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "6644ab16-5740-483d-93eb-561438afdefc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['go',\n",
       " 'jurong',\n",
       " 'point',\n",
       " 'crazy',\n",
       " 'available',\n",
       " 'bugis',\n",
       " 'great',\n",
       " 'world',\n",
       " 'la',\n",
       " 'buffet',\n",
       " 'cine',\n",
       " 'got',\n",
       " 'amore',\n",
       " 'wat']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a81305fd-4ad2-4749-aafc-8b065ef989ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create our own word2veg model\n",
    "import gensim\n",
    "model=gensim.models.Word2Vec(words,window=5,min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e8c4dcc6-0ee1-4ad7-8899-111cf3eb30fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'get'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.index_to_key[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "35caa5b8-291b-4363-9c5d-f7725a9e7cd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "cef072ff-797b-411d-bb02-e056dc38c3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('see', 0.9972472786903381),\n",
       " ('ok', 0.9971683621406555),\n",
       " ('great', 0.9971197843551636),\n",
       " ('even', 0.9971122741699219),\n",
       " ('sat', 0.9971115589141846),\n",
       " ('age', 0.9970937371253967),\n",
       " ('well', 0.9970886707305908),\n",
       " ('dear', 0.9970799684524536),\n",
       " ('getting', 0.9970791339874268),\n",
       " ('come', 0.9970752596855164)]"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similar_by_word('kid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e17b7d54-d60a-4b95-b90e-9ba80093e9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_avgword2vec(doc):\n",
    "    return np.mean([model.wv[word] for word in doc if word in model.wv.index_to_key],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "e20dc25e-f873-42ea-9322-04dd821ac456",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "aafdc152-b03b-452f-a195-06d65b6b5d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/5567 [00:00<?, ?it/s]C:\\Users\\LENOVO\\anaconda34\\Lib\\site-packages\\numpy\\core\\fromnumeric.py:3504: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\LENOVO\\anaconda34\\Lib\\site-packages\\numpy\\core\\_methods.py:129: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "100%|████████████████████████████████████████████████████████████████████████████| 5567/5567 [00:01<00:00, 4215.64it/s]\n"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "for i in tqdm(range(len(words))):\n",
    "        X.append(get_avgword2vec(word[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bdf50d5a-5e04-49c9-b8ba-ec617c0adf46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "8dd1bb54-4c03-4a4e-9ad3-b3a98c2ad189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final X shape: (5543, 100)\n",
      "Final Y shape: (5543,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "X_clean = []\n",
    "Y_clean = []\n",
    "\n",
    "for xi, yi in zip(X, Y):\n",
    "    # Keep only valid embedding vectors\n",
    "    if isinstance(xi, np.ndarray) and xi.shape == (100,) and not np.isnan(xi).any():\n",
    "        X_clean.append(xi)\n",
    "        Y_clean.append(yi)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X_clean = np.vstack(X_clean)\n",
    "Y_clean = np.array(Y_clean)\n",
    "\n",
    "print(\"Final X shape:\", X_clean.shape)\n",
    "print(\"Final Y shape:\", Y_clean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1dca98f3-73b5-4492-8723-716c47a52098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.16498606,  0.33908898,  0.09407058,  0.02612874,  0.05088136,\n",
       "       -0.44670323,  0.08778512,  0.5521626 , -0.16010366, -0.14853522,\n",
       "       -0.1251679 , -0.38522068, -0.02650948,  0.02990146,  0.06912044,\n",
       "       -0.26679474,  0.00960262, -0.44419363, -0.07829234, -0.5343945 ,\n",
       "        0.09883003,  0.15860878,  0.0548018 , -0.11943758, -0.16474062,\n",
       "        0.02319697, -0.24430531, -0.15554431, -0.25523788,  0.07557369,\n",
       "        0.31840545,  0.04203333,  0.05949235, -0.20271495, -0.09493458,\n",
       "        0.32250065,  0.07110686, -0.26352742, -0.2420361 , -0.5387395 ,\n",
       "       -0.00203975, -0.30152068, -0.03236288,  0.05417456,  0.17058143,\n",
       "       -0.12186601, -0.12228891, -0.09523246,  0.1120327 ,  0.20945197,\n",
       "        0.1813032 , -0.29512137, -0.07012452, -0.06894106, -0.22879355,\n",
       "        0.0629842 ,  0.21293436, -0.00835697, -0.39260957,  0.07971463,\n",
       "        0.07809349,  0.09433075, -0.10955591,  0.03666303, -0.2791009 ,\n",
       "        0.2585687 ,  0.12831971,  0.20629749, -0.3273433 ,  0.33577344,\n",
       "       -0.28026178,  0.15467992,  0.33590052, -0.05718226,  0.28733417,\n",
       "        0.18939537, -0.10400935,  0.00177882, -0.24340412,  0.06650303,\n",
       "       -0.16069897, -0.05416331, -0.2752001 ,  0.4008198 , -0.09735612,\n",
       "       -0.07090475, -0.01498361,  0.45300993,  0.37217084,  0.09861106,\n",
       "        0.45484027,  0.19886528,  0.02577737,  0.06539918,  0.46699002,\n",
       "        0.3068908 ,  0.17804289, -0.3132164 ,  0.04055114, -0.06037924],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "17e6bc89-efd4-429d-a315-7de04e5c19de",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = message[list(map(lambda x: len(x)>0 ,corpus))]\n",
    "Y=pd.get_dummies(Y['label'])\n",
    "Y=Y.iloc[:,1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "4965799d-c634-450e-818c-97ce095aca9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## train test split \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,Y_train,Y_test=train_test_split(X,Y,test_size=0.2,random_state=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "61143468-556c-48c9-a56e-f8a28af7a9b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4453,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[142], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mensemble\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomForestClassifier\n\u001b[0;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m RandomForestClassifier()\n\u001b[1;32m----> 4\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, Y_train)\n",
      "File \u001b[1;32m~\\anaconda34\\Lib\\site-packages\\sklearn\\base.py:1473\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1466\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1468\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1469\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1470\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1471\u001b[0m     )\n\u001b[0;32m   1472\u001b[0m ):\n\u001b[1;32m-> 1473\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda34\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py:363\u001b[0m, in \u001b[0;36mBaseForest.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[0;32m    361\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msparse multilabel-indicator for y is not supported.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 363\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    364\u001b[0m     X,\n\u001b[0;32m    365\u001b[0m     y,\n\u001b[0;32m    366\u001b[0m     multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[0;32m    367\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    368\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mDTYPE,\n\u001b[0;32m    369\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    370\u001b[0m )\n\u001b[0;32m    371\u001b[0m \u001b[38;5;66;03m# _compute_missing_values_in_feature_mask checks if X has missing values and\u001b[39;00m\n\u001b[0;32m    372\u001b[0m \u001b[38;5;66;03m# will raise an error if the underlying tree base estimator can't handle missing\u001b[39;00m\n\u001b[0;32m    373\u001b[0m \u001b[38;5;66;03m# values. Only the criterion is required to determine if the tree supports\u001b[39;00m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;66;03m# missing values.\u001b[39;00m\n\u001b[0;32m    375\u001b[0m estimator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mestimator)(criterion\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion)\n",
      "File \u001b[1;32m~\\anaconda34\\Lib\\site-packages\\sklearn\\base.py:650\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    648\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    649\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 650\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    651\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda34\\Lib\\site-packages\\sklearn\\utils\\validation.py:1301\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1296\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1297\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1298\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1299\u001b[0m     )\n\u001b[1;32m-> 1301\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1302\u001b[0m     X,\n\u001b[0;32m   1303\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1304\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1305\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1306\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1307\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1308\u001b[0m     force_writeable\u001b[38;5;241m=\u001b[39mforce_writeable,\n\u001b[0;32m   1309\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1310\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1311\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1312\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1313\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1314\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1315\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1316\u001b[0m )\n\u001b[0;32m   1318\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1320\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda34\\Lib\\site-packages\\sklearn\\utils\\validation.py:1012\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1010\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1011\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1012\u001b[0m         array \u001b[38;5;241m=\u001b[39m _asarray_with_order(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype, xp\u001b[38;5;241m=\u001b[39mxp)\n\u001b[0;32m   1013\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m   1014\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1015\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m   1016\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda34\\Lib\\site-packages\\sklearn\\utils\\_array_api.py:751\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    749\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    750\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 751\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39masarray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    753\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    754\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    755\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (4453,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "41d736c8-fabc-43ba-bcda-f6b37f468339",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[143], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape, Y\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape, X_test\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(X.shape, Y.shape)\n",
    "print(X_train.shape, X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23797e80-7865-419a-b1f7-1b17cabeeafe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
